{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e612513a",
   "metadata": {},
   "source": [
    "# BUNDESDATA RAG \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b29fce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from typing import Any, List \n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ollama._types import ResponseError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35864d7e",
   "metadata": {},
   "source": [
    "## Daten laden und vorbereiten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76fbc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEURL = \"https://verkehr.autobahn.de/o/autobahn\"\n",
    "SERVICES = [\n",
    "    \"roadworks\",\n",
    "    \"parking_lorry\",\n",
    "    \"warning\",\n",
    "    \"closure\",\n",
    "    \"electric_charging_station\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51da19",
   "metadata": {},
   "source": [
    "**stringify_all_fields:**\n",
    "Conversion of a python object (dict) into string required for document indexing and processing using langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0ef81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_all_fields(obj: Any) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True) #ensure ascii=False to handle special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6478c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(payload: Any, service: str) -> List[Any]:\n",
    "    # if payload is a dict with the service as a key and the value is a list, return that list\n",
    "    if isinstance(payload, dict) and isinstance(payload.get(service), list):\n",
    "        return payload[service]\n",
    "    # if payload is already a list, return it directly\n",
    "    if isinstance(payload, list):\n",
    "        return payload\n",
    "    return [payload]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07476368",
   "metadata": {},
   "source": [
    "**to_documents:**\n",
    "Helper to convert the json response (dict) into langchain documents using the stringify_all_fields() function to get a text representation of all fields.\n",
    "Additionally, we capture data about the road_id, service, title, description to give unique markers to roads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aa2ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_documents(road_id: str, service: str, items: List[Any], source_url: str) -> List[Document]:\n",
    "    docs: List[Document] = [] # initialize empty list\n",
    "    for i, item in enumerate(items):\n",
    "        # define title and description\n",
    "        title = \"\"\n",
    "        description = \"\"\n",
    "        if isinstance(item, dict):\n",
    "            title = item.get(\"title\", \"\") or item.get(\"name\", \"\") # if title is empty, try name\n",
    "            description = item.get(\"description\", \"\") or item.get(\"text\", \"\") # if description is empty, try text\n",
    "\n",
    "        page_content = \"\\n\".join(\n",
    "            # structured content\n",
    "            [\n",
    "                f\"road: {road_id}\",\n",
    "                f\"service: {service}\",\n",
    "                (f\"title: {title}\" if title else \"\"),\n",
    "                (f\"description: {description}\" if description else \"\"),\n",
    "                \"\",\n",
    "                \"ALL_FIELDS_JSON:\",\n",
    "                # use stringify_all_fields to convert item to string\n",
    "                stringify_all_fields(item),\n",
    "            ]\n",
    "        ).strip()\n",
    "        # create document and add to list\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=page_content,\n",
    "                metadata={\n",
    "                    \"road_id\": road_id,\n",
    "                    \"service\": service,\n",
    "                    \"source_url\": source_url,\n",
    "                    \"item_index\": i,\n",
    "                    \"title\": title,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6eb36",
   "metadata": {},
   "source": [
    "**build_documents():**\n",
    "This function does the API calls. We go through all road ids and services (endpoints) available and convert them into a list of langchain documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48657df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_documents() -> List[Document]:\n",
    "    docs: List[Document] = [] # initialize empty list\n",
    "    with requests.Session() as s:\n",
    "        # get list of roads\n",
    "        roads_resp = s.get(BASEURL, timeout=20)\n",
    "        roads_resp.raise_for_status()\n",
    "        roads = roads_resp.json()[\"roads\"]\n",
    "        # iterate over roads and services\n",
    "        for road_id in roads:\n",
    "            for service in SERVICES:\n",
    "                # fetch service data for every road\n",
    "                url = f\"{BASEURL}/{road_id}/services/{service}\"\n",
    "                resp = s.get(url, timeout=20)\n",
    "                resp.raise_for_status()\n",
    "                # get payload\n",
    "                payload = resp.json()\n",
    "                # extract items with helper function\n",
    "                items = get_items(payload, service)\n",
    "                docs.extend(to_documents(road_id, service, items, url)) # convert to documents with helper function\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cd6048",
   "metadata": {},
   "source": [
    "## Embedding Model initialisieren (mit dem Uni-Ollama-Server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6bae58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_URL = \"http://132.199.138.16:11434\"\n",
    "LLM_MODEL = \"gpt-oss:20b\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59700610",
   "metadata": {},
   "source": [
    "***Split text using RecursiveCharacterTextSplitter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5bfbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25201\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\", \",\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "docs = build_documents()\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(splitted_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60164fe7",
   "metadata": {},
   "source": [
    "***add_in_batches():***\n",
    "\n",
    "We encountered a EOF status code: 500 Error during the embedding request. To fix this, we batched the documents in even smaller batches (batch_size = 64 here) to avoid the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b954bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_batches(\n",
    "    vectorstore: Chroma,\n",
    "    docs: List[Document],\n",
    "    batch_size: int = 64,\n",
    "    max_retries: int = 3,\n",
    "):\n",
    "    \n",
    "    total = len(docs)\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = docs[start : start + batch_size]\n",
    "\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                vectorstore.add_documents(batch)\n",
    "                break\n",
    "            except ResponseError as e:\n",
    "                if attempt == max_retries:\n",
    "                    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9aee6",
   "metadata": {},
   "source": [
    "***Initialize Ollama-Embedding-Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86285e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in Chroma: 25201\n"
     ]
    }
   ],
   "source": [
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    base_url=LLM_URL\n",
    ")\n",
    "\n",
    "try:\n",
    "    vectorstore.delete_collection()\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"autobahn-rag\", embedding_function=ollama_embeddings)\n",
    "\n",
    "add_in_batches(\n",
    "    vectorstore,\n",
    "    splitted_docs,\n",
    "    batch_size = 32,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "print(\"Docs in Chroma:\", vectorstore._collection.count())\n",
    "\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "403aed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=LLM_MODEL,\n",
    "    base_url=LLM_URL,\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37649338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Parkplatz auf der A93\n",
      "\n",
      "[ANSWER]: **Parkplatz auf der A93 – Zusammenfassung aus dem Kontext**\n",
      "\n",
      "| Segment | Lage des Parkplatzes | Relevante Informationen |\n",
      "|---------|-----------------------|-------------------------|\n",
      "| **A93 – Inntal → Nicklheim** | „A93: Rosenheim → Kiefersfelden, zwischen 0,9 km hinter AD Inntal und 1,3 km vor Nicklheim“ | • **Parking‑Area**: Der Parkplatz liegt unmittelbar vor dem Ort „Nicklheim“. <br>• **Verkehrssituation**: Baustelle ist für die Zeiträume **11. Februar 2026 von 08:00 bis 14:00 Uhr** gültig. <br>• **Baustelleneigenschaften**: Länge 1 km, maximale Fahrgeschwindigkeit 80 km/h, maximale Durchfahrtsbreite 4 m. <br>• **Zweck**: „A93 von Inntal (AD) nach Nicklheim (Parkplatz) Unterhaltungsarbeiten“ – d.h. die Arbeiten betreffen den Abschnitt bis zum Parkplatz. |\n",
      "\n",
      "**Was im Kontext nicht enthalten ist**\n",
      "\n",
      "* **Andere Parkplätze**: Der Text nennt nur den Parkplatz vor Nicklheim; weitere Parkplätze auf der A93 werden nicht erwähnt.  \n",
      "* **Ladestationen**: Es gibt keine Angabe zu elektrischen Ladestationen im Zusammenhang mit dem Parkplatz.  \n",
      "* **Warnungen**: Es liegen keine speziellen Warnungen für den Parkplatz vor.  \n",
      "* **Sicherheitsinformationen**: Keine Hinweise auf Sicherheitsvorschriften für Parkplätze.  \n",
      "\n",
      "**Kurzantwort**\n",
      "\n",
      "Der einzige im Kontext erwähnte Parkplatz auf der A93 befindet sich vor Nicklheim (zwischen 0,9 km hinter AD Inntal und 1,3 km vor Nicklheim). Für den 11. Februar 2026 sind dort Baustellenarbeiten von 08:00 bis 14:00 Uhr geplant, die bis zum Parkplatz reichen. Weitere Parkplätze, Ladestationen oder spezifische Warnungen werden im gegebenen Kontext nicht genannt.\n"
     ]
    }
   ],
   "source": [
    "question = \"Parkplatz auf der A93\"\n",
    "context_docs = vector_retriever.invoke(question)\n",
    "context = \"\\n\\n---\\n\\n\".join(d.page_content for d in context_docs)\n",
    "\n",
    "prompt = (\n",
    "        \"Beantworte die Frage mit Kontext. \"\n",
    "        \"Wenn Informationen fehlen, sage, was im Kontext nicht enthalten ist, aber antworte trotzdem so weit wie möglich.\\n\\n\"\n",
    "        \"Falls die Frage deutsche Begriffe enthält, suche im Kontext nach folgenden englischen Begriffen: parking lorries - Parkplätze, closures - Sperrungen, electric charging stations - Ladestationen, warnings - Warnungen, roadworks - Baustellen\"\n",
    "        f\"Frage: {question}\\n\\n\"\n",
    "        f\"Kontext:\\n{context}\"\n",
    "    )\n",
    "\n",
    "answer = llm.invoke(prompt)\n",
    "print(\"\\nQuestion:\", question)\n",
    "print(\"\\n[ANSWER]:\", answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53bf200",
   "metadata": {},
   "source": [
    "## Gradio UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fbfe1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def rag_answer(question: str):\n",
    "    # Aufruf für Retriever\n",
    "    context_docs = vector_retriever.invoke(question)\n",
    "\n",
    "    # alle docs zu einem String zusammenfügen\n",
    "    context = \"\\n\\n---\\n\\n\".join(d.page_content for d in context_docs)\n",
    "\n",
    "    # Prompt bauen\n",
    "    prompt = (\n",
    "        \"Beantworte die Frage mit Kontext. \"\n",
    "        \"Wenn Informationen fehlen, sage, was im Kontext nicht enthalten ist, aber antworte trotzdem so weit wie möglich.\\n\\n\"\n",
    "        \"Falls die Frage deutsche Begriffe enthält, suche im Kontext nach folgenden englischen Begriffen: parking lorries - Parkplätze, closures - Sperrungen, electric charging stations - Ladestationen, warnings - Warnungen, roadworks - Baustellen\"\n",
    "        f\"Frage: {question}\\n\\n\"\n",
    "        f\"Kontext:\\n{context}\"\n",
    "    )\n",
    "\n",
    "    # LLM Aufruf mit prompt\n",
    "    answer = llm.invoke(prompt)\n",
    "\n",
    "    return answer.content\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"Bundesdata RAG\") as demo:\n",
    "    gr.Markdown(\"Autobahn Bundesdata RAG\")\n",
    "    gr.Markdown(\n",
    "        \"Stelle eine Frage zum Thema deutsche Autobahnen. \"\n",
    "        \"Es wird Kontext via Retriever geholt und das LLM antwortet soweit möglich aus dem Kontext. \"\n",
    "        \"Im Kontext vorhandene Themenbereiche sind roadworks, parkinglorries, warnings, closures und electric charging stations.\"\n",
    "    )\n",
    "\n",
    "    question_in = gr.Textbox(\n",
    "        label=\"Stelle deine Frage\",\n",
    "        placeholder=\"z.B. gib mir alle Warnings auf der A93\",\n",
    "        lines=2,\n",
    "    )\n",
    "\n",
    "    ask_btn = gr.Button(\"Antwort generieren\")\n",
    "\n",
    "    answer_out = gr.Textbox(\n",
    "        label=\"Antwort\",\n",
    "        lines=10,\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "   \n",
    "\n",
    "    ask_btn.click(\n",
    "        fn=rag_answer,\n",
    "        inputs=question_in,\n",
    "        outputs=[answer_out],\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bundesdata-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
